<!DOCTYPE html>
<!-- Created by pdf2htmlEX (https://github.com/coolwanglu/pdf2htmlex) -->
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta charset="utf-8"/>

<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
<link rel="stylesheet" href="base.min.css"/>
<link rel="stylesheet" href="fancy.min.css"/>
<link rel="stylesheet" href="main.css"/>
<script src="compatibility.min.js"></script>
<script src="theViewer.min.js"></script>
<script>
try{
theViewer.defaultViewer = new theViewer.Viewer({});
}catch(e){}
</script>
<title></title>
</head>
<body>
<div id="sidebar">
<div id="outline">
</div>
</div>
<div id="page-container">
<div id="pf1" class="pf w0 h0" data-page-no="1"><div class="pc pc1 w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bg1.png"/><div class="t m0 x1 h1 y1 ff1 fs0 fc0 sc0 ls0 ws0">Music Genre </div><div class="t m0 x2 h1 y2 ff1 fs0 fc0 sc0 ls0 ws0">Classification</div><div class="t m0 x3 h2 y3 ff1 fs1 fc0 sc0 ls0 ws0">Submitted by:</div><div class="t m0 x4 h2 y4 ff1 fs1 fc0 sc0 ls0 ws0">Oscar Poudel (<span class="fc1">op72@njit.edu</span>)</div><div class="t m0 x5 h2 y5 ff1 fs1 fc0 sc0 ls0 ws0">Cong Qi(<span class="fc1">cq5@njit.edu</span>)</div><div class="t m0 x6 h2 y6 ff1 fs1 fc0 sc0 ls0 ws0">Submitted to:</div><div class="t m0 x7 h2 y7 ff1 fs1 fc0 sc0 ls0 ws0">Pr. Mark CartWright</div><div class="t m0 x8 h2 y8 ff1 fs1 fc0 sc0 ls0 ws0">(<span class="fc1">mc232@njit.edu</span>)</div><div class="t m0 x9 h3 y9 ff1 fs2 fc0 sc0 ls0 ws0">CS 698 Machine Listening</div><div class="t m0 xa h3 ya ff1 fs2 fc0 sc0 ls0 ws0">FINAL PROJECT </div><a class="l" href="mailto:op72@njit.edu"><div class="d m1" style="border-style:none;position:absolute;left:201.028809px;bottom:124.726334px;width:116.358398px;height:20.109375px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="mailto:cq5@njit.edu"><div class="d m1" style="border-style:none;position:absolute;left:182.528809px;bottom:95.286331px;width:105.336914px;height:20.109375px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="mailto:mc232@njit.edu"><div class="d m1" style="border-style:none;position:absolute;left:738.644287px;bottom:90.359940px;width:130.341797px;height:20.109375px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf2" class="pf w0 h0" data-page-no="2"><div class="pc pc2 w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bg2.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Introduction</div><div class="t m0 xb h5 yc ff1 fs4 fc1 sc0 ls0 ws0">• <span class="ff2 fs5 fc2 sc1">Music Genre Classification <span class="_ _0"></span><span class="ff3 sc0">is a project that aims to develop a robust and </span></span></div><div class="t m0 xc h5 yd ff3 fs5 fc2 sc0 ls0 ws0">accurate system for classifying music genres . Our system will analyze various </div><div class="t m0 xc h5 ye ff3 fs5 fc2 sc0 ls0 ws0">characteristics of music such as tempo, rhythm, pitch, timbre, and spectral </div><div class="t m0 xc h5 yf ff3 fs5 fc2 sc0 ls0 ws0">feature. The project has potential to contribute significantly to the field of </div><div class="t m0 xc h5 y10 ff3 fs5 fc2 sc0 ls0 ws0">music information retrieval<span class="_ _1"></span>. Our main goal is not only to create a system that </div><div class="t m0 xc h5 y11 ff3 fs5 fc2 sc0 ls0 ws0">can accurately classify music genres, but also to gain deeper insights into </div><div class="t m0 xc h5 y12 ff3 fs5 fc2 sc0 ls0 ws0">what characteristics define and differentiate various music genres</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf3" class="pf w0 h0" data-page-no="3"><div class="pc pc3 w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bg3.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Motivation</div><div class="t m0 xb h6 y13 ff1 fs6 fc1 sc0 ls0 ws0">•<span class="_ _2"> </span><span class="ff3 fs7 fc2">Enhancing Genre Classification Accuracy:</span></div><div class="t m0 xd h7 y14 ff1 fs8 fc1 sc0 ls0 ws0">•<span class="_ _3"> </span><span class="ff3 fs9 fc2">Desire to improve accuracy due to complexity and variability in traditional systems.</span></div><div class="t m0 xd h7 y15 ff1 fs8 fc1 sc0 ls0 ws0">•<span class="_ _3"> </span><span class="ff3 fs9 fc2">Ensemble techniques employed to amalgamate predictions and enhance classification accuracy.</span></div><div class="t m0 xb h6 y16 ff1 fs6 fc1 sc0 ls0 ws0">•<span class="_ _2"> </span><span class="ff3 fs7 fc2">Applications and Benefits:</span></div><div class="t m0 xd h7 y17 ff1 fs8 fc1 sc0 ls0 ws0">•<span class="_ _3"> </span><span class="ff3 fs9 fc2">Motivated by potential applications, especially in music recommendation systems.</span></div><div class="t m0 xd h7 y18 ff1 fs8 fc1 sc0 ls0 ws0">•<span class="_ _3"> </span><span class="ff3 fs9 fc2">Accurate genre classification can lead to more personalized and satisfying user experiences.</span></div><div class="t m0 xb h6 y19 ff1 fs6 fc1 sc0 ls0 ws0">•<span class="_ _2"> </span><span class="ff3 fs7 fc2">Intellectual Curiosity and Academic Motivation:</span></div><div class="t m0 xd h7 y1a ff1 fs8 fc1 sc0 ls0 ws0">•<span class="_ _3"> </span><span class="ff3 fs9 fc2">Driven by intellectual curiosity and academic pursuit.</span></div><div class="t m0 xd h7 y1b ff1 fs8 fc1 sc0 ls0 ws0">•<span class="_ _3"> </span><span class="ff3 fs9 fc2">Opportunity to delve deeper into machine listening and deep learning.</span></div><div class="t m0 xb h6 y1c ff1 fs6 fc1 sc0 ls0 ws0">•<span class="_ _2"> </span><span class="ff3 fs7 fc2">Holistic Perspective:</span></div><div class="t m0 xd h7 y1d ff1 fs8 fc1 sc0 ls0 ws0">•<span class="_ _3"> </span><span class="ff3 fs9 fc2">Project incorporates technical challenges, practical applications, and academic exploration.</span></div><div class="t m0 xd h7 y1e ff1 fs8 fc1 sc0 ls0 ws0">•<span class="_ _3"> </span><span class="ff3 fs9 fc2">Comprehensive approach for a meaningful impact on music genre classification.</span></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf4" class="pf w0 h0" data-page-no="4"><div class="pc pc4 w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bg4.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Datset</div><div class="t m0 xb h8 y1f ff2 fs2 fc0 sc2 ls0 ws0">GTZAN Dataset</div><div class="t m0 xb h9 y20 ff1 fsa fc1 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff3 fsb fc0">Comprises 1000 audio tracks each lasting 30 seconds..</span></div><div class="t m0 xb h9 y21 ff1 fsa fc1 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff3 fsb fc0">Each track is a 30-second clip stored as a 22050Hz Mono 16-bit audio </span></div><div class="t m0 xc h9 y22 ff3 fsb fc0 sc0 ls0 ws0">file in .wav format.</div><div class="t m0 xb h9 y23 ff1 fsa fc1 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff3 fsb fc0">Extracted features used for genre classification.</span></div><div class="t m0 xb h9 y24 ff1 fsa fc1 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff3 fsb fc0">Dataset contains 10 genres, each with 100 tracks.</span></div><div class="t m0 xb h9 y25 ff1 fsa fc1 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff3 fsb fc0">Genres: Blues, Classical, Country, Disco, Hiphop, Jazz, Metal, Pop, </span></div><div class="t m0 xc h9 y26 ff3 fsb fc0 sc0 ls0 ws0">Reggae, Rock.</div><div class="t m0 xb h9 y27 ff1 fsa fc1 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff3 fsb fc0">Dataset had pre extracted mfcc features and csv file with calculated </span></div><div class="t m0 xc h9 y28 ff3 fsb fc0 sc0 ls0 ws0">mean and variance of various features (3sc and 30 sec) </div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf5" class="pf w0 h0" data-page-no="5"><div class="pc pc5 w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bg5.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Datset</div><div class="t m0 xb h5 y29 ff2 fs5 fc0 sc2 ls0 ws0">FMA Dataset</div><div class="t m0 xb h3 y2a ff4 fsc fc1 sc0 ls0 ws0">+<span class="_ _5"></span><span class="ff1 fs2 fc0">FMA (Free Music Archive)</span></div><div class="t m0 xb h3 y2b ff4 fsc fc1 sc0 ls0 ws0">+<span class="_ _5"></span><span class="ff1 fs2 fc0">8000 tracks of 30 seconds</span></div><div class="t m0 xb h3 y2c ff4 fsc fc1 sc0 ls0 ws0">+<span class="_ _5"></span><span class="ff1 fs2 fc0">8 balanced genres</span></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf6" class="pf w0 h0" data-page-no="6"><div class="pc pc6 w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bg6.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Exploration (Gtzan)</div><div class="t m0 xb h8 y2d ff1 fsc fc1 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff3 fs2 fc2">Blues Sample:</span></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf7" class="pf w0 h0" data-page-no="7"><div class="pc pc7 w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bg7.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Exploration (GTZAN)</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf8" class="pf w0 h0" data-page-no="8"><div class="pc pc8 w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bg8.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Exploration (GTZAN)</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf9" class="pf w0 h0" data-page-no="9"><div class="pc pc9 w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bg9.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Exploration(FMA)</div><div class="t m0 xe h2 y2e ff1 fs1 fc0 sc0 ls0 ws0">The duration distribution of each track in FMA<span class="_ _7"> </span>The genre distribution of the track in FMA</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pfa" class="pf w0 h0" data-page-no="a"><div class="pc pca w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bga.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Starting With Audio File </div><div class="t m0 xf ha y2f ff1 fsd fc0 sc0 ls0 ws0">•<span class="_ _1"></span><span class="fse">Segment </span></div><div class="t m0 xf ha y30 ff1 fsd fc0 sc0 ls0 ws0">•<span class="_ _1"></span><span class="fse">Data Extraction</span></div><div class="t m0 x10 hb y31 ff1 fsf fc3 sc0 ls0 ws0">MfCC  </div><div class="t m0 x11 hb y32 ff1 fsf fc3 sc0 ls0 ws0">Extraction</div><div class="t m0 x12 ha y33 ff1 fsd fc0 sc0 ls0 ws0">•<span class="_ _1"></span><span class="fse">Adam(0.0004)</span></div><div class="t m0 x12 ha y34 ff1 fsd fc0 sc0 ls0 ws0">•<span class="_ _1"></span><span class="fse">Spare categorical </span></div><div class="t m0 x13 hc y35 ff1 fse fc0 sc0 ls0 ws0">crossentropy</div><div class="t m0 x14 hb y36 ff1 fsf fc3 sc0 ls0 ws0">CNN</div><div class="t m0 x15 ha y37 ff1 fsd fc0 sc0 ls0 ws0">•<span class="_ _1"></span><span class="fse">72%</span></div><div class="t m0 x16 hb y38 ff1 fsf fc3 sc0 ls0 ws0">Accuracy</div><div class="t m0 x17 hd y39 ff3 fs1 fc0 sc0 ls0 ws0">Input Shape: The input shape of the model is (130, 13, 1), representing the </div><div class="t m0 x17 hd y3a ff3 fs1 fc0 sc0 ls0 ws0">dimensions of the input MFCCs.</div><div class="t m0 x17 hd y3b ff3 fs1 fc0 sc0 ls0 ws0">Model Parameters: The model consists of 33,242 total parameters, with 32,954 </div><div class="t m0 x17 hd y3c ff3 fs1 fc0 sc0 ls0 ws0">trainable parameters and 288 non-trainable parameters.</div><div class="t m0 x17 hd y3d ff3 fs1 fc0 sc0 ls0 ws0">Activation Functions: ReLU activation is used in convolutional and dense layers, while </div><div class="t m0 x17 hd y3e ff3 fs1 fc0 sc0 ls0 ws0">softmax activation is employed in the output layer.</div><div class="t m0 x18 h2 y3f ff1 fs1 fc0 sc0 ls0 ws0">Fig: CNN for </div><div class="t m0 x18 h2 y40 ff1 fs1 fc0 sc0 ls0 ws0">GTZAN</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pfb" class="pf w0 h0" data-page-no="b"><div class="pc pcb w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bgb.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Results from CNN</div><div class="t m0 x19 he y41 ff1 fs4 fc1 sc0 ls0 ws0">• <span class="fs5 fc0">We got the accuracy of 72.31% </span></div><div class="t m0 x1a hf y42 ff1 fs5 fc0 sc0 ls0 ws0">with CNN model</div><div class="t m0 x19 he y43 ff1 fs4 fc1 sc0 ls0 ws0">• <span class="fs5 fc0">Comparative to “Music Genre </span></div><div class="t m0 x1a hf y44 ff1 fs5 fc0 sc0 ls0 ws0">Classification Using A </div><div class="t m0 x1a hf y45 ff1 fs5 fc0 sc0 ls0 ws0">Convolutional Neural Network </div><div class="t m0 x1a hf y46 ff1 fs5 fc1 sc0 ls0 ws0">38954030.pdf (stanford.edu)<span class="_ _0"></span><span class="fc0">” </span></div><div class="t m0 x1a hf y47 ff1 fs5 fc0 sc0 ls0 ws0">which got around 75% with the </div><div class="t m0 x1a hf y48 ff1 fs5 fc0 sc0 ls0 ws0">base model</div><a class="l" href="https://cs230.stanford.edu/projects_spring_2020/reports/38954030.pdf"><div class="d m1" style="border-style:none;position:absolute;left:67.503769px;bottom:223.826645px;width:353.376968px;height:31.281250px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pfc" class="pf w0 h0" data-page-no="c"><div class="pc pcc w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bgc.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Starting With CSV File</div><div class="t m0 x1b h8 y49 ff1 fsc fc0 sc0 ls0 ws0">•<span class="_ _8"> </span><span class="ff3 fs2">Easier to perform classification (less computing </span></div><div class="t m0 x1c h8 y4a ff3 fs2 fc0 sc0 ls0 ws0">intensive)</div><div class="t m0 x1b h8 y4b ff1 fsc fc0 sc0 ls0 ws0">•<span class="_ _8"> </span><span class="ff3 fs2">Tested across multiple machine learning model:’</span></div><div class="t m0 x1b h8 y4c ff1 fsc fc0 sc0 ls0 ws0">•<span class="_ _8"> </span><span class="ff3 fs2">Xg boost got the best of the result among the </span></div><div class="t m0 x1c h8 y4d ff3 fs2 fc0 sc0 ls0 ws0">machine learning models  with 90 percent </div><div class="t m0 x1c h8 y4e ff3 fs2 fc0 sc0 ls0 ws0">accuracy which was big shift from the accuracy </div><div class="t m0 x1c h8 y4f ff3 fs2 fc0 sc0 ls0 ws0">we got from the CNN starting from the audio file</div><div class="t m0 xb h10 y50 ff1 fs7 fc0 sc0 ls0 ws0">Machine learning Models (GTZAN)</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pfd" class="pf w0 h0" data-page-no="d"><div class="pc pcd w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bgd.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Starting With CSV File</div><div class="t m0 x1b h8 y51 ff1 fsc fc0 sc0 ls0 ws0">•<span class="_ _8"> </span><span class="ff3 fs2">Built 4 model with different parameters</span></div><div class="t m0 x1b h8 y52 ff1 fsc fc0 sc0 ls0 ws0">•<span class="_ _8"> </span><span class="ff3 fs2">Tried changing model parameters and adding </span></div><div class="t m0 x1c h8 y53 ff3 fs2 fc0 sc0 ls0 ws0">dropout layers which increased the accuracy </div><div class="t m0 x1c h8 y54 ff3 fs2 fc0 sc0 ls0 ws0">models</div><div class="t m0 x1b h8 y55 ff1 fsc fc0 sc0 ls0 ws0">•<span class="_ _8"> </span><span class="ff3 fs2">Got 92% accuracy with model 3  having </span></div><div class="t m0 x1c h8 y56 ff3 fs2 fc0 sc0 ls0 ws0">434,442 parameters </div><div class="t m0 x1b h8 y57 ff1 fsc fc0 sc0 ls0 ws0">•<span class="_ _8"> </span><span class="ff3 fs2">Model 4 had 2 mil parameters</span></div><div class="t m0 xb hf y58 ff1 fs5 fc0 sc0 ls0 ws0">Deep Learning Models</div><div class="t m0 x1d hd y59 ff3 fs1 fc0 sc0 ls0 ws0">Architecture for model 3:</div><div class="t m0 x1e hd y5a ff3 fs1 fc0 sc0 ls0 ws0">Dense(512, activation=&apos;relu&apos;)</div><div class="t m0 x1e hd y5b ff3 fs1 fc0 sc0 ls0 ws0">Dropout(0.2)</div><div class="t m0 x1e hd y5c ff3 fs1 fc0 sc0 ls0 ws0">Dense(256, activation=&apos;relu&apos;)</div><div class="t m0 x1e hd y5d ff3 fs1 fc0 sc0 ls0 ws0">Dropout(0.2)</div><div class="t m0 x1e hd y5e ff3 fs1 fc0 sc0 ls0 ws0">Dense(128, activation=&apos;relu&apos;)</div><div class="t m0 x1e hd y5f ff3 fs1 fc0 sc0 ls0 ws0">Dropout(0.2)</div><div class="t m0 x1e hd y60 ff3 fs1 fc0 sc0 ls0 ws0">Dense(64, activation=&apos;relu&apos;)</div><div class="t m0 x1e hd y61 ff3 fs1 fc0 sc0 ls0 ws0">Dropout(0.2)</div><div class="t m0 x1e hd y62 ff3 fs1 fc0 sc0 ls0 ws0">Dense(10, activation=&apos;softmax&apos;)</div><div class="t m0 x1d hd y63 ff3 fs1 fc0 sc0 ls0 ws0">Total Parameters: 434,442</div><div class="t m0 x1d hd y64 ff3 fs1 fc0 sc0 ls0 ws0">Optimizer: SGD (epochs=700)</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pfe" class="pf w0 h0" data-page-no="e"><div class="pc pce w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bge.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Model for FMA</div><div class="t m0 xb hf y65 ff4 fs4 fc1 sc0 ls0 ws0">+<span class="ff1 fs5 fc0">Procedure</span></div><div class="t m0 xd h3 y66 ff5 fsc fc1 sc0 ls0 ws0">o<span class="_ _9"> </span><span class="ff1 fs2 fc4">The raw audio files are first preprocessed to extract meaningful </span></div><div class="t m0 x1f h3 y67 ff1 fs2 fc4 sc0 ls0 ws0">features that can be used as input to the CNN model. In this case, we </div><div class="t m0 x1f h3 y68 ff1 fs2 fc4 sc0 ls0 ws0">are extracting Mel-Frequency Cepstral Coefficients (MFCCs), which </div><div class="t m0 x1f h3 y69 ff1 fs2 fc4 sc0 ls0 ws0">are a common feature used in audio processing tasks.</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pff" class="pf w0 h0" data-page-no="f"><div class="pc pcf w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bgf.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Model for FMA</div><div class="t m0 xb hf y6a ff4 fs4 fc1 sc0 ls0 ws0">+<span class="ff1 fs5 fc0">Procedure</span></div><div class="t m0 xd h3 y6b ff5 fsc fc1 sc0 ls0 ws0">o<span class="_ _9"> </span><span class="ff6 fs2 fc4">Loading Audio:<span class="_ _a"></span><span class="ff1"> Each audio file is loaded, typically keeping a </span></span></div><div class="t m0 x1f h3 y6c ff1 fs2 fc4 sc0 ls0 ws0">consistent duration (e.g., first 30 seconds of each track) and sample </div><div class="t m0 x1f h3 y6d ff1 fs2 fc4 sc0 ls0 ws0">rate.</div><div class="t m0 xd h3 y6e ff5 fsc fc1 sc0 ls0 ws0">o<span class="_ _9"> </span><span class="ff6 fs2 fc4">Extracting MFCCs:<span class="ff1"> MFCCs are extracted from the audio data. This </span></span></div><div class="t m0 x1f h3 y6f ff1 fs2 fc4 sc0 ls0 ws0">involves converting the raw audio signal into the frequency domain and </div><div class="t m0 x1f h3 y70 ff1 fs2 fc4 sc0 ls0 ws0">then into the Mel scale, followed by taking the log of the powers at each </div><div class="t m0 x1f h3 y71 ff1 fs2 fc4 sc0 ls0 ws0">Mel frequency.</div><div class="t m0 xd h3 y72 ff5 fsc fc1 sc0 ls0 ws0">o<span class="_ _9"> </span><span class="ff6 fs2 fc4">Padding:<span class="ff1"> Since the duration of audio files might vary, the extracted </span></span></div><div class="t m0 x1f h3 y73 ff1 fs2 fc4 sc0 ls0 ws0">MFCCs are padded to ensure that they all have the same shape, which </div><div class="t m0 x1f h3 y74 ff1 fs2 fc4 sc0 ls0 ws0">is necessary for batching in neural networks. In this case, the padding </div><div class="t m0 x1f h3 y75 ff1 fs2 fc4 sc0 ls0 ws0">is done to reach a shape of [13, 2048] for each sample.</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf10" class="pf w0 h0" data-page-no="10"><div class="pc pc10 w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bg10.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Model for FMA</div><div class="t m0 xb hf y76 ff4 fs4 fc1 sc0 ls0 ws0">+<span class="ff1 fs5 fc0">Defining the CNN Model</span></div><div class="t m0 xd h3 y77 ff5 fsc fc1 sc0 ls0 ws0">o<span class="_ _9"> </span><span class="ff6 fs2 fc4">Model Architecture:<span class="_ _b"></span><span class="ff1"> The CNN model is defined with convolutional </span></span></div><div class="t m0 x1f h3 y78 ff1 fs2 fc4 sc0 ls0 ws0">layers, pooling layers, and fully connected layers. The convolutional </div><div class="t m0 x1f h3 y79 ff1 fs2 fc4 sc0 ls0 ws0">layers extract spatial hierarchies of features from the MFCCs, and the </div><div class="t m0 x1f h3 y7a ff1 fs2 fc4 sc0 ls0 ws0">fully connected layers make the final classification.</div><div class="t m0 xd h3 y7b ff5 fsc fc1 sc0 ls0 ws0">o<span class="_ _9"> </span><span class="ff6 fs2 fc4">Input Shape:<span class="ff1"> The input to the CNN is the preprocessed MFCCs, </span></span></div><div class="t m0 x1f h3 y7c ff1 fs2 fc4 sc0 ls0 ws0">reshaped to include a channel dimension, resulting in a shape of </div><div class="t m0 x1f h3 y7d ff1 fs2 fc4 sc0 ls0 ws0">[batch_size, 1, 13, 2048].</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf11" class="pf w0 h0" data-page-no="11"><div class="pc pc11 w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bg11.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Model for FMA</div><div class="t m0 xb hf y65 ff4 fs4 fc1 sc0 ls0 ws0">+<span class="ff1 fs5 fc0">Result (Accuracy)</span></div><div class="t m0 xd h3 y7e ff5 fsc fc1 sc0 ls0 ws0">o<span class="_ _9"> </span><span class="ff1 fs2 fc0">Logistic Regression: 0.55</span></div><div class="t m0 xd h3 y7f ff5 fsc fc1 sc0 ls0 ws0">o<span class="_ _9"> </span><span class="ff1 fs2 fc0">MLP:0.67</span></div><div class="t m0 xd h3 y80 ff5 fsc fc1 sc0 ls0 ws0">o<span class="_ _9"> </span><span class="ff1 fs2 fc0">CNN: 0.875</span></div><div class="t m0 xd h3 y81 ff5 fsc fc1 sc0 ls0 ws0">o<span class="_ _9"> </span><span class="ff1 fs2 fc0">The CNN model has the best result.</span></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf12" class="pf w0 h0" data-page-no="12"><div class="pc pc12 w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bg12.png"/><div class="t m0 xb h4 yb ff1 fs3 fc0 sc0 ls0 ws0">Conclusion</div><div class="t m0 x20 h8 y82 ff2 fs2 fc0 sc2 ls0 ws0">Opportunities for Improvement:</div><div class="t m0 x20 h8 y83 ff1 fsc fc1 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff2 fs2 fc0 sc2">Hyperparameter Tuning:<span class="ff3 sc0"> Experiment with learning rates, layer configurations, and dropout </span></span></div><div class="t m0 x4 h8 y84 ff3 fs2 fc0 sc0 ls0 ws0">rates.</div><div class="t m0 x20 h8 y85 ff1 fsc fc1 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff2 fs2 fc0 sc2">Data Augmentation:<span class="ff3 sc0"> Enhance model robustness through data augmentation techniques.</span></span></div><div class="t m0 x20 h8 y86 ff1 fsc fc1 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff2 fs2 fc0 sc2">Ensemble Models:<span class="ff3 sc0"> Explore ensemble methods for further performance boost</span></span></div><div class="t m0 xb h8 y87 ff2 fs2 fc0 sc2 ls0 ws0">Key Takeaways:</div><div class="t m0 xb h8 y88 ff1 fsc fc0 sc0 ls0 ws0">•<span class="ff3 fs2">Developed a functional Music Genre Classification system.</span></div><div class="t m0 xb h8 y89 ff1 fsc fc0 sc0 ls0 ws0">•<span class="ff3 fs2">Demonstrated proficiency in audio data processing and CNN modeling.</span></div><div class="t m0 xb h8 y8a ff1 fsc fc0 sc0 ls0 ws0">•<span class="ff3 fs2">Opportunities for future enhancements and exploration.</span></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf13" class="pf w0 h0" data-page-no="13"><div class="pc pc13 w0 h0"><img class="bi x0 y0 w0 h0" alt="" src="bg13.png"/><div class="t m0 x21 h11 y8b ff1 fs10 fc0 sc0 ls0 ws0">THANK YOU !!</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
</div>
<div class="loading-indicator">

</div>
</body>
</html>
